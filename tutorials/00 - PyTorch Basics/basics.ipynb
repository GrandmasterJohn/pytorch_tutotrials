{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.1479 -1.4306 -0.6625\n",
      "-0.8837 -0.3919  0.4596\n",
      " 1.0206  0.3912  0.4879\n",
      "-1.2130 -2.0117 -0.7249\n",
      " 0.8625  1.3113 -0.5966\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random normal\n",
    "x = torch.randn(5, 3)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a layer\n",
    "linear = nn.Linear(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.2596 -0.3333  0.2803\n",
      "-0.1326 -0.0936 -0.2235\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "Parameter containing:\n",
      " 0.0273\n",
      " 0.3186\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sess weight and bias\n",
    "print (linear.weight)\n",
    "print (linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.3568  0.5810\n",
      " 0.0573  0.3698\n",
      " 0.2986  0.0376\n",
      " 0.1797  0.8299\n",
      "-0.3530  0.2149\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# forward propagate\n",
    "y = linear(Variable(x))\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert numpy array to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  2\n",
      " 3  4\n",
      "[torch.LongTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert numpy array to tensor\n",
    "a = np.array([[1,2], [3,4]])\n",
    "b = torch.from_numpy(a)\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image Preprocessing \n",
    "transform = transforms.Compose([\n",
    "    transforms.Scale(40),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# download and loading dataset f\n",
    "train_dataset = dsets.CIFAR10(root='./data/',\n",
    "                               train=True, \n",
    "                               transform=transform,\n",
    "                               download=True)\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "print (image.size())\n",
    "print (label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data loader provides queue and thread in a very simple way\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                               batch_size=100, \n",
    "                               shuffle=True,\n",
    "                               num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration start then queue and thread start\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# mini-batch images and labels\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    # your training code will be written here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) What about custom dataset not cifar10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        lst_features = [[i*10+j for j in range(3)] for i in range(6)]\n",
    "        self.features = torch.FloatTensor(lst_features)\n",
    "        self.targets = torch.IntTensor([i for i in range(6)])\n",
    "        \n",
    "    # You should build the following two functions:\n",
    "    # __len__: provides the size of the dataset,\n",
    "    # __getitem__: return a sample data for given index\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.targets[index]\n",
    "    def __len__(self):\n",
    "        return self.features.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset()\n",
    "custom_loader = data.DataLoader(dataset=custom_dataset,\n",
    "                                batch_size=3, \n",
    "                                shuffle=True,\n",
    "                                num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: \n",
      " 50  51  52\n",
      "  0   1   2\n",
      " 30  31  32\n",
      "[torch.FloatTensor of size 3x3]\n",
      " \n",
      " 5\n",
      " 0\n",
      " 3\n",
      "[torch.LongTensor of size 3]\n",
      "\n",
      "batch 1: \n",
      " 10  11  12\n",
      " 20  21  22\n",
      " 40  41  42\n",
      "[torch.FloatTensor of size 3x3]\n",
      " \n",
      " 1\n",
      " 2\n",
      " 4\n",
      "[torch.LongTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_index, (feature, target) in enumerate(custom_loader):\n",
    "    print ('batch {}: {} {}'.format(batch_index, feature, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also create an dataset by using data.TensorDataset\n",
    "lst_features = [[i*10+j for j in range(3)] for i in range(6)]\n",
    "features = torch.FloatTensor(lst_features)\n",
    "targets = torch.IntTensor([i for i in range(6)])\n",
    "my_data = data.TensorDataset(features, targets)\n",
    "train_loader = data.DataLoader(my_data, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: \n",
      " 30  31  32\n",
      " 50  51  52\n",
      "[torch.FloatTensor of size 2x3]\n",
      " \n",
      " 3\n",
      " 5\n",
      "[torch.LongTensor of size 2]\n",
      "\n",
      "batch 1: \n",
      " 40  41  42\n",
      " 10  11  12\n",
      "[torch.FloatTensor of size 2x3]\n",
      " \n",
      " 4\n",
      " 1\n",
      "[torch.LongTensor of size 2]\n",
      "\n",
      "batch 2: \n",
      " 20  21  22\n",
      "  0   1   2\n",
      "[torch.FloatTensor of size 2x3]\n",
      " \n",
      " 2\n",
      " 0\n",
      "[torch.LongTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_index, (feature, target) in enumerate(train_loader):\n",
    "    print ('batch {}: {} {}'.format(batch_index, feature, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download and load pretrained model\n",
    "resnet = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1000])\n",
      "torch.Size([10, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# delete top layer for finetuning\n",
    "sub_model = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "# for test\n",
    "images = Variable(torch.randn(10, 3, 256, 256))\n",
    "print (resnet(images).size())\n",
    "print (sub_model(images).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save and load the trained model\n",
    "torch.save(sub_model, 'model.pkl')\n",
    "\n",
    "model = torch.load('model.pkl')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
